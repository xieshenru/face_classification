# face_classification
In this R&amp;D Project we propose to implement a general convolutional neural network (CNN) building framework for designing real-time CNNs. We validate our models by creating a real-time vision system which accomplishes the tasks of face detection, gender classification and emotion classification simultaneously in one blended step using our proposed CNN architecture. After presenting the details of the training procedure setup we proceed to evaluate on standard benchmark sets. We report accuracies of 93% in the IMDB gender dataset and 65.67% in the FER-2013 emotion dataset. The GEMEP-FERA database is a subset of the GEMEP corpus used as database for the FERA 2011 challenge It consists of recordings of 10 actors displaying a range of expressions. There are seven subjects in the training data, and six subjects in the test set. The training set contains 155 image sequences and the testing contains 134 image sequences. There are in total five emotion categories in the database: Anger, Fear, Happiness, Relief and Sadness. We extract static frames from the sequences with six basic expressions, which resulted to in around 7,000 images. We have proposed and tested a general building designs for creating real-time CNNs. Our proposed architectures have been systematically built in order to reduce the number of parameters. We began by eliminating completely the fully connected layers and by reducing the number of parameters in the remaining convolutional layers via depth-wise separable convolutions. We have shown that our proposed models can be stacked for multi-class classifications while maintaining real-time inferences. Specifically, we have developed a vision system that performs face detection, gender classification and emotion classification in a single integrated module. We have achieved human-level performance in our classifications tasks using a single CNN that leverages modern architecture constructs.
